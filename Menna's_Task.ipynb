{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install snscrape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fh8NIxVwxjsZ",
        "outputId": "48100f96-af25-4033-97a0-8b2e0de4f145"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: snscrape in /usr/local/lib/python3.10/dist-packages (0.7.0.20230622)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from snscrape) (2.31.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from snscrape) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from snscrape) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from snscrape) (3.13.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->snscrape) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->snscrape) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "nokmkJ-WwzU-"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import snscrape.modules.twitter as sntwitter\n",
        "from snscrape.base import ScraperException  # Import ScraperException\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to check for stock mentions in a tweet\n",
        "def has_stock_mention(tweet, ticker):\n",
        "  return any(word.startswith(\"$\") and word[1:].isalpha() and len(word[1:]) <= 4 for word in tweet.content.split())\n"
      ],
      "metadata": {
        "id": "qgmeO82GxO2s"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input parameters\n",
        "twitter_accounts = [\n",
        "    \"https://twitter.com/Mr_Derivatives\",\n",
        "    \"https://twitter.com/warrior_0719\",\n",
        "    \"https://twitter.com/ChartingProdigy\",\n",
        "    \"https://twitter.com/allstarcharts\",\n",
        "    \"https://twitter.com/yuriymatso\",\n",
        "    \"https://twitter.com/TriggerTrades\",\n",
        "    \"https://twitter.com/AdamMancini4\",\n",
        "    \"https://twitter.com/CordovaTrades\",\n",
        "    \"https://twitter.com/Barchart\",\n",
        "    \"https://twitter.com/RoyLMattox\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "UqoDSTxCxp1X"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"$TSLA\"  # Replace with your desired ticker symbol\n",
        "interval_minutes = 2  # Change this to your desired scraping interval"
      ],
      "metadata": {
        "id": "k9sl4rb0xt1O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to perform scraping and display results\n",
        "def scrape_and_display():\n",
        "  # Track mentions for the ticker\n",
        "  mentions_count = 0\n",
        "  start_time = datetime.now()\n"
      ],
      "metadata": {
        "id": "T98IT5t4xyEF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through each Twitter account\n",
        "for account_url in twitter_accounts:\n",
        "  username = account_url.split(\"/\")[-1]\n"
      ],
      "metadata": {
        "id": "3WNAVqsIx0VU"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "retry_count = 0\n",
        "max_retries = 5\n",
        "retry_delay = 10  # seconds"
      ],
      "metadata": {
        "id": "9KarI5TPzAgL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while retry_count < max_retries:\n",
        "    try:\n",
        "        for tweet in sntwitter.TwitterSearchScraper(f\"from:{username}\").get_items():\n",
        "            if has_stock_mention(tweet, ticker):\n",
        "                mentions_count += 1\n",
        "        break  # No exceptions, so break out of the loop\n",
        "    except ScraperException as e:\n",
        "        print(f\"Encountered error: {e}\")\n",
        "        print(f\"Retrying in {retry_delay} seconds...\")\n",
        "        time.sleep(retry_delay)\n",
        "        retry_count += 1\n",
        "else:\n",
        "    print(\"Max retries reached. Exiting...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeghvEDxx2Ag",
        "outputId": "d08e846b-8eee-47d8-d39d-e7f802032aa6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:snscrape.base:Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "CRITICAL:snscrape.base:4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encountered error: 4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Retrying in 10 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:snscrape.base:Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "CRITICAL:snscrape.base:4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encountered error: 4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Retrying in 10 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:snscrape.base:Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "CRITICAL:snscrape.base:4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encountered error: 4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Retrying in 10 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:snscrape.base:Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "CRITICAL:snscrape.base:4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encountered error: 4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Retrying in 10 seconds...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:snscrape.base:Error retrieving https://api.twitter.com/1.1/guest/activate.json: non-200 response (429)\n",
            "CRITICAL:snscrape.base:4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "CRITICAL:snscrape.base:Errors: non-200 response (429), non-200 response (429), non-200 response (429), non-200 response (429)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encountered error: 4 requests to https://api.twitter.com/1.1/guest/activate.json failed, giving up.\n",
            "Retrying in 10 seconds...\n",
            "Max retries reached. Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate elapsed time\n",
        "  elapsed_time = datetime.now() - start_time"
      ],
      "metadata": {
        "id": "QYp3LQfpyEhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Display results\n",
        "  print(f\"{ticker} was mentioned {mentions_count} times in the last {elapsed_minutes} minutes.\")\n"
      ],
      "metadata": {
        "id": "9cM6SvuAyFSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Schedule scraping every X minutes using a loop\n",
        "while True:\n",
        "  scrape_and_display()\n",
        "  # Sleep for the desired interval before next scrape\n",
        "  time.sleep(interval_minutes * 60)"
      ],
      "metadata": {
        "id": "HjCz73i9yIgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}